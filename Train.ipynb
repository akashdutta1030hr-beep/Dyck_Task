{
  "nbformat": 4,
  "nbformat_minor": 4,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dyck Task - Training (Google Colab)\n",
        "\n",
        "Fine-tune DeepSeek-R1-Distill-Qwen-1.5B on Dyck sequence completion with reasoning. Run cells in order.\n",
        "\n",
        "**Colab:** Upload `conversation.jsonl` or mount Drive and set `DATA_PATH` accordingly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Optional: Install dependencies (uncomment if needed on Colab)\n",
        "# !pip install -q torch transformers datasets unsloth bitsandbytes peft accelerate trl matplotlib"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import Dataset\n",
        "from unsloth import FastLanguageModel\n",
        "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
        "\n",
        "# ============================================================================\n",
        "# Configuration\n",
        "# ============================================================================\n",
        "MODEL_NAME = \"unsloth/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
        "DATA_PATH = \"conversation.jsonl\"  # Upload this file or set to your path (e.g. /content/drive/MyDrive/conversation.jsonl)\n",
        "OUTPUT_DIR = \"results\"\n",
        "MAX_LENGTH = 2048\n",
        "DATASET_SIZE = 10000"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================================\n",
        "# Model Setup\n",
        "# ============================================================================\n",
        "print(\"Loading model and tokenizer...\")\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=MODEL_NAME,\n",
        "    max_seq_length=MAX_LENGTH,\n",
        "    dtype=torch.float16,\n",
        "    load_in_4bit=True,\n",
        ")\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=32,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_alpha=64,\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    use_gradient_checkpointing=True,\n",
        "    random_state=42,\n",
        ")\n",
        "print(\"Model loaded.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================================\n",
        "# Dataset Loading\n",
        "# ============================================================================\n",
        "print(f\"Loading dataset from {DATA_PATH}...\")\n",
        "data = []\n",
        "with open(DATA_PATH, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        if line.strip():\n",
        "            data.append({\"text\": line.strip()})\n",
        "dataset = Dataset.from_list(data)\n",
        "print(f\"Loaded {len(dataset)} samples\")\n",
        "\n",
        "dataset = dataset.shuffle(seed=42)\n",
        "dataset = dataset.train_test_split(test_size=0.05)\n",
        "train_dataset = dataset[\"train\"]\n",
        "eval_dataset = dataset[\"test\"]\n",
        "print(f\"Train: {len(train_dataset)}, Eval: {len(eval_dataset)}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================================\n",
        "# Preprocessing Function\n",
        "# ============================================================================\n",
        "def preprocess(example):\n",
        "    text_content = example.get(\"text\", \"\").strip()\n",
        "    if isinstance(text_content, str):\n",
        "        while text_content.startswith('\"'):\n",
        "            text_content = text_content[1:]\n",
        "        while text_content.endswith('\"'):\n",
        "            text_content = text_content[:-1]\n",
        "        text_content = text_content.strip()\n",
        "        try:\n",
        "            conversation = json.loads(text_content)\n",
        "        except json.JSONDecodeError:\n",
        "            start_idx = text_content.find('[')\n",
        "            end_idx = text_content.rfind(']')\n",
        "            if start_idx != -1 and end_idx != -1 and end_idx > start_idx:\n",
        "                conversation = json.loads(text_content[start_idx:end_idx+1])\n",
        "            else:\n",
        "                raise ValueError(f\"Failed to parse JSON: {text_content[:100]}...\")\n",
        "    else:\n",
        "        conversation = text_content\n",
        "\n",
        "    user_msg = None\n",
        "    assistant_msg = None\n",
        "    for msg in conversation:\n",
        "        if msg.get(\"role\") == \"user\":\n",
        "            user_msg = msg\n",
        "        elif msg.get(\"role\") == \"assistant\":\n",
        "            assistant_msg = msg\n",
        "\n",
        "    user_content = user_msg.get(\"content\", \"\")\n",
        "    assistant_reasoning = assistant_msg.get(\"reasoning_content\", \"\").strip()\n",
        "    assistant_completion = assistant_msg.get(\"content\", \"\").strip()\n",
        "    if assistant_reasoning and assistant_completion:\n",
        "        assistant_content = f\"{assistant_reasoning}\\n\\nFINAL ANSWER: {assistant_completion}\"\n",
        "    else:\n",
        "        assistant_content = assistant_completion or assistant_reasoning\n",
        "\n",
        "    messages = [{\"role\": \"user\", \"content\": user_content}, {\"role\": \"assistant\", \"content\": assistant_content}]\n",
        "    full_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n",
        "    user_text = tokenizer.apply_chat_template([messages[0]], tokenize=False, add_generation_prompt=False)\n",
        "    user_tokenized = tokenizer(user_text, truncation=True, max_length=MAX_LENGTH, padding=True, add_special_tokens=True)\n",
        "    assistant_start_idx = len(user_tokenized[\"input_ids\"])\n",
        "    tokenized = tokenizer(full_text, truncation=True, max_length=MAX_LENGTH, padding=False, add_special_tokens=True)\n",
        "    input_ids = tokenized[\"input_ids\"]\n",
        "    labels = [-100] * len(input_ids)\n",
        "    assistant_start_idx = min(assistant_start_idx, len(input_ids))\n",
        "    for i in range(assistant_start_idx, len(input_ids)):\n",
        "        if input_ids[i] != tokenizer.pad_token_id:\n",
        "            labels[i] = input_ids[i]\n",
        "    pad_id = tokenizer.pad_token_id\n",
        "    current_len = len(input_ids)\n",
        "    if current_len < MAX_LENGTH:\n",
        "        padding_len = MAX_LENGTH - current_len\n",
        "        input_ids = input_ids + [pad_id] * padding_len\n",
        "        labels = labels + [-100] * padding_len\n",
        "        attention_mask = [1] * current_len + [0] * padding_len\n",
        "    else:\n",
        "        attention_mask = [1] * MAX_LENGTH\n",
        "    tokenized[\"input_ids\"] = input_ids\n",
        "    tokenized[\"labels\"] = labels\n",
        "    tokenized[\"attention_mask\"] = attention_mask\n",
        "    return tokenized"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Apply preprocessing (use num_proc=1 or 2 on Colab if you get multiprocessing errors)\n",
        "print(\"Preprocessing training dataset...\")\n",
        "train_dataset = train_dataset.map(preprocess, remove_columns=train_dataset.column_names, desc=\"Preprocessing train\", num_proc=2)\n",
        "print(\"Preprocessing evaluation dataset...\")\n",
        "eval_dataset = eval_dataset.map(preprocess, remove_columns=eval_dataset.column_names, desc=\"Preprocessing eval\", num_proc=2)\n",
        "\n",
        "if len(train_dataset) > 0:\n",
        "    sample = train_dataset[0]\n",
        "    trainable_labels = sum(1 for label in sample[\"labels\"] if label != -100)\n",
        "    print(f\"Preprocessing validated. Assistant tokens (loss on): {trainable_labels}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================================\n",
        "# Training Setup\n",
        "# ============================================================================\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=50,\n",
        "    save_steps=50,\n",
        "    logging_steps=30,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=2,\n",
        "    learning_rate=2e-5,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_ratio=0.1,\n",
        "    weight_decay=0.005,\n",
        "    bf16=True,\n",
        "    max_grad_norm=1.0,\n",
        "    save_total_limit=1,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "print(\"Trainer ready.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================================\n",
        "# Training\n",
        "# ============================================================================\n",
        "print(\"Starting training...\")\n",
        "trainer.train()\n",
        "\n",
        "print(f\"\\nSaving model to {OUTPUT_DIR}...\")\n",
        "model.save_pretrained(OUTPUT_DIR)\n",
        "tokenizer.save_pretrained(OUTPUT_DIR)\n",
        "print(f\"Model saved to {OUTPUT_DIR}\")\n",
        "\n",
        "print(\"\\nFinal evaluation...\")\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Final eval loss: {eval_results.get('eval_loss', 'N/A'):.4f}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================================\n",
        "# Plot Training Loss\n",
        "# ============================================================================\n",
        "history = trainer.state.log_history\n",
        "train_losses = [log['loss'] for log in history if 'loss' in log and 'step' in log]\n",
        "train_steps = [log['step'] for log in history if 'loss' in log and 'step' in log]\n",
        "eval_losses = [log['eval_loss'] for log in history if 'eval_loss' in log and 'step' in log]\n",
        "eval_steps = [log['step'] for log in history if 'eval_loss' in log and 'step' in log]\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "if train_losses:\n",
        "    plt.plot(train_steps, train_losses, label='Training Loss', marker='o', markersize=3, linewidth=1.5)\n",
        "if eval_losses:\n",
        "    plt.plot(eval_steps, eval_losses, label='Evaluation Loss', marker='s', markersize=3, linewidth=1.5)\n",
        "plt.xlabel('Training Steps')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Evaluation Loss')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{OUTPUT_DIR}/training_loss.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(f\"Saved {OUTPUT_DIR}/training_loss.png\")\n",
        "print(\"Training complete!\")"
      ],
      "outputs": [],
      "execution_count": null
    }
  ]
}
